ItzLit
LEON LI, Carolyn thio, justin lee, crystal nguyen, john gamboa and alexandra huang,  University of California, San Diego
INTRODUCTION
Many techniques for 2D flow visualization have been developed and applied. These include grids of little arrows, still the most common for many applications, equally spaced streamlines [Turk and Banks 1996, Jobard and Lefer 1997], and line integral convolution (LIC) [Cabral and Leedom 1993]. But which is best and why? [Laidlaw et al. 2001] showed that the “which is best” question can be answered by means of user studies in which participants are asked to carry out tasks such as tracing advection pathways or finding critical points in the flow field. (Note: An advection pathway is the same as a streamline in a steady flow field.) [Ware 2008] proposed that the “why” question may be answered through the application of recent theories of the way contours in the environment are processed in the visual cortex of the brain. But Ware only provided a descriptive sketch with minimal detail and no formal expression. In the present paper, we show, through a numerical model of neural processing in the cortex, how the theory predicts which methods will be best for an advection path tracing task.
The IBQ Approach in Image Quality Estimation
The IBQ approach combined with psychometric methods has proven suitable, especially for testing the performance of imaging devices or their components and then returning this quality information to the product development or evaluation stages. When the subjective changes in image quality are multivariate, the technical parameters changing in the test image are unknown or difficult to compute. However, the IBQ approach can be used to determine the subjectively important quality dimensions with a wide range of natural image material related to changes caused by different devices or their components. In order to tune the image-processing components for optimal performance, it is important to know what the subjectively crucial characteristics that change in the perceived image quality are as a function of the tuning parameters, or simply for different components. Table I describes the problems caused by multivariate changes in image quality and offers suggestions of how to approach them by using different measurement methods that complement each other. The IBQ approach can complement the psychometric approaches and objective measurements by defining the subjective meaning of image quality attributes and characteristics; in other words, it reveals how important they are for the overall perceived quality. This information can then be used as guidance in tuning, and no complex models are needed in order to understand the relation between objective measures and subjective quality ratings.

Table I.  Multivariate Changes in Image Quality Attributes, the Relationship of Psychometric and  Objective Image Quality Estimations and the IBQ Approach

The IBQ approach can help to determine the subjectively crucial characteristics of an image and therefore to give weights to objective  and computational measures.

Our basic rational is as follows. Tracing an advection pathway for a particle dropped in a flow field is a perceptual task that can be carried out with the aid of a visual representation of the flow. The task requires that an individual attempts to trace a continuous contour from some designated starting point in the flow until some terminating condition is realized. This terminating condition might be the edge of the flow field or the crossing of some designated boundary. If we can produce a neurologically plausible model of contour perception then this may be the basis of a rigorous theory of flow visualization efficiency.

Identify.  Characteristics of an object.
Locate.  Absolute or relative position.
Distinguish.  Recognize as the same or different.
Categorize.  Classify according to some property (e.g., color, position, or shape).  
Cluster.  Group same or related objects together.
Distribution. Describe the overall pattern.
Rank.  Order objects of like types.
Compare.  Evaluate different objects with each other.
Associate.  Join in a relationship.
Correlate.  A direct connection.
Conditions
The reproduction of the gestures was performed in the presence or absence of visual and auditory feedback, resulting in four (2 x 2) conditions

Visual and auditory feedback (V + A). 
Visual feedback, no auditory feedback (V).
Auditory feedback, no visual feedback (A).
No visual or auditory feedback (None).

The order of the four conditions was randomized across participants.

when + where ⇒ what: State the properties of an object or objects at a certain time, or set of times, and a certain place, or set of places.
when + what ⇒ where: State the location or set of locations.
where + what  ⇒ when: State the time or set of times.

When conducting a user study, the goal for the study is to measure the suitability of the visualization in some sense. What is actually measured is a fundamental question that we believe can be handled by using the concepts of effectiveness, efficiency, and satisfaction. These three concepts are derived from the ISO standard of usability 9241-11.
Extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency, and satisfaction in a specified context of use.
The mechanisms of contour perception have been studied by psychologists for at least 80 years, starting with the Gestalt psychologists. A major breakthrough occurred with the work of Hubel and Wiesel [Hubel and Wiesel 1962, Hubel and Wiesel 1968] and from that time, neurological theories of contour perception developed. In this article, we show that a model of neural processing in the visual cortex can be used to predict which flow representation methods will be better. Our model has two stages. The first is a contour enhancement model. Contour enhancement is achieved through lateral connections between nearby local edge detectors. This produces a neural map in which continuous contours have an enhanced representation. The model or cortical processing we chose to apply is adapted from [Li 1998]. The second stage is a contour integration model. This represents a higher level cognitive process whereby a pathway is traced.
Theorem 1.1. For a video sequence of n frames, an optimal approach based on dynamic programming can retrieve all levels of key frames together with their temporal boundaries in O(n4) times.
We apply the model to a set of 2D flow visualization methods that were previously studied by [Laidlaw et al. 2001]. This allows us to carry out a qualitative comparison between the model and how humans actually performed. We evaluated the model against human performance in an experiment in which humans and the model performed the same task.
Our article is organized as follows. First we summarize what is known about the cortical processing of contours and introduce Li's [Li 1998] model of the cortex. Next we show how a slightly modified version of Li's model differentially enhances various flow rendering methods. Following this, we develop a perceptual model of advection tracing and show how it predicts different outcomes for an advection path-tracing task based on the prior work of [Laidlaw et al. 2001]. Finally we discuss how this work relates to other work that has applied perceptual modeling to data visualization and suggest other uses of the general method.
CORTICAL PROCESSING OF CONTOURS
Visual information passes along the optic nerve from the retina of the eye where it is relayed, via a set of synaptic junctions in the midbrain lateral geniculate nucleus, to the primary visual cortex at the back or the brain (Visual Area 1 or V1). It has been known since the Hubel and Wiesel's work in the 60s that the visual cortex contains billions of neurons that are sensitive to oriented edges and contours in the light falling on the retina. Such neurons have localized receptive fields each responding to the orientation information contained within the light imaged in a small patch of retina. A widely used mathematical model of a V1 neuron's receptive field is the Gabor function [Daugman 1985]:
	(1)
Hubel and Wiesel [Hubel and Wiesel 1962, Hubel and Wiesel 1968] found that neurons responding to similar orientations were clustered together in a structure they called a column which extended from the surface of the visual cortex to the white matter (see Figure 1). Later, they and other researchers discovered hypercolumn structures consisting of thousands of neurons all responding to the same area of visual space and selecting for a range of orientations. Overall, V1 contains a topographic map of the visual field having the property that every part of the retinal image is processed in parallel for all orientations. These orientation selective neurons have provided the basis for all subsequent theories of contour and edge detection.
	                                     

Fig. 1. Neurons are arranged in V1 in a column architecture. Neurons in a particular column respond preferentially to the same edge orientation. Moving across the cortex (by a minute amount) yields columns responding to edges having different orientations. A hypercolumn is a section of cortex that represents a complete set of orientations for a particular location in space.
There remains the problem of how the output of orientation sensitive neurons, each responding to different parts of a visual contour, becomes combined to represent the whole contour. Part of the solution appears to be a contour enhancement mechanism. [Field et al. 1993] examined the human's ability to perceive a contour composed of discrete oriented elements. They placed a contour composed of separated Gabor patches, among a field of randomly orientated Gabor patches. Contours were detected when the patches were smoothly aligned. They were not detected when there was misalignment. This work suggests that there is some manner of lateral coupling among the visual elements involved in perceiving the Gabor patches in the contour. These researchers have suggested that similarly oriented aligned contours mutually excite one another, while they inhibit other neurons that are nearby (Figure 2).
                                                                          
Fig. 2. Neurons whose receptive fields are aligned along a continuous contour mutually reinforce each other. They inhibit nearby neurons with a similar orientation sensitivity.
LI'S V1 MODEL
Based on the observed organization of the neurons in the visual cortex by Hubel and Wiesel [Hubel and Wiesel 1962, Hubel and Wiesel 1968] and the experimental evidence by [Field et al. 1993], Zhaoping Li constructed a simplified model of the behavior of V1 neurons and examined the model's ability to integrate contours across multiple V1 neurons. The model is introduced briefly here, and described in more detail in [Li 1998]. In Li's model, the cortex is approximated by a set of hypercolumns arranged in a hexagonal grid. Each hexagonal cell has 12 orientation-selective neuron pairs oriented in 15-degree increments. One of the main simplifications embodied in Li's model is that it fails to incorporate the way the mammalian visual systems scales with respect to the fovea. Real neural architectures have much smaller receptive fields near the fovea at the center of vision than at the edges of the visual field. The neurons in each hex cell were grouped into excitatory and inhibitory pairs responding to an edge of a particular orientation at that location. Thus there were a total of 24 neurons per cell. The firing rates of both the inhibitory and excitatory neurons were modeled with real values. The neuron pairs affected neighboring neuron pairs via a transfer function that depended on the alignment of the edge selectivity orientations. Neuron pairs that were aligned with one another exhibited an excitatory effect on each other, while pairs that were not aligned inhibited each other. Finally, Li's model also contains feedback pathways for higher-level visual areas to influence individual neurons.
In our implementation, the mapping of the hexagonal grid to the image space was such that the hex centers were separated by 10 pixels. For the V1 neuron response, we used the Gabor function (Eq. (1)) with a wavelength, λ, of 21 pixels, a σ  of 7 pixels, and an aspect ratio, γ, of 1.
STREAMLINE TRACING ALGORITHM
[Laidlaw et al. 2001] compared the effectiveness of visualization techniques by presenting test subjects with the task of estimating where a particle placed in the center of a flow field would exit a circle. Six different flow-field visualization methods were assessed by comparing the difference between the actual exit numerically calculated and the estimation of the exit by the human subjects. Laidlaw et al.'s experiment was carried out on humans but, in our work, we apply this evaluation technique to humans as well as to our model of the human visual system and use a streamline tracing algorithm to trace the path of the particle.
We use the term streamline tracing to describe the higher level process that must exist for people to judge a streamline pathway. We call it streamline tracing because the task seems to require the user to make a series of judgments, starting at the center, whereby the path of a particle dropped in the center is integrated in a stepwise pattern to the edge of the field. Though many algorithms exist in the machine vision literature for contour tracing, we found these to be inappropriate for use in this application. Contour tracing algorithms are generally designed to trace out the boundary of some shape but a streamline tracing algorithm must also be able able to produce a streamline in a field of disconnected contours, such as is the case with the regular arrows. The streamline to be traced will often not follow a visible contour but instead be locate between contours, and will sometimes pass through areas devoid of visual elements. Thus we developed a specialized algorithm that is capable of tracing streamlines that do not necessarily correspond to the boundary of any shape but can pass between visual contours.
Perception is a combination of top-down and bottom-up processes. Bottom-up processes are driven by information on the retina and are what is simulated by Li's model [Li 1998]. Top-down processes are much more varied and are driven in the brain by activation from regions in the frontal and temporal cortex that are known to be involved in the control of pattern identification and attention [Lund 2001]. All of the flow visualizations evaluated by [Laidlaw et al. 2001], except for LIC, contain symbolic information regarding the direction of flow along the contour elements (e.g. an arrowhead). In a perpetual/cognitive process this would be regarded as a top-down influence. At present our model does not deal with symbolic direction information but it does do streamline tracing once set in the right general direction.
Streamline tracing is a combination of top-down and bottom-up processes. Broadly speaking, top-down processes reflect task demands and the bottom-up processes reflect environmental information. In our case, the bottom-up information comes from the different types of visualization, while the top-down information is an attempt to model the cognitive process of streamline pathway tracing. Contour integration was modeled using the following iterative algorithm.
ALGORITHM 1: Iterative Algorithm
current_position  ← center
current_direction  ← up
current_position  is inside circle
while current_position is inside circle, do
	neighborhood  ← all grid hexes within two hexes from current_position
	for each hex in neighborhood, do 
		for each neuron in hex do
		      convert neuron_orientation to vector
		      scale vector by neuron_excitation
	            vector_sum  ← vector_sum + vector
             end 
      end
     normalize vector_sum
     current_position  ← current_position + vector_sum
     current_direction  ← vector_sum
     return current_position 
end

The algorithm maintains a context that contains a current position and direction. Initially, the position is the center, and the direction set to upward. This context models the higher-order, top-down influence on the algorithm that results from the task requirements (tracing from the center dot) and the directionality which in our experiment was set to be always in an upwardly trending direction.
The algorithm traces the contour by repeatedly estimating the flow direction at the current_position  and moving the position a small distance (.5 hex radii) in that direction. The flow direction is calculated from the neural responses in the local neighborhood of the current_position. The excitation of each neuron is used to generate a vector whose length is proportional to the strength of the response and whose orientation is given by the receptive field orientation. Because receptive field orientations are ambiguous as to direction (for any vector aligned with the receptive field, its negative is similarly aligned). The algorithm chose the vector most closely corresponding to the vector computed on the previous iteration. Vectors are computed for all neurons in hypercolumns within a 2-hexes radius of the current position; they are summed and normalized to generate the next current_position.
Some changes were made from the method published by [Pineo and Ware 2008]. Previously, the algorithm considered only a single hex cell at each iteration of the algorithm. We found that this would occasionally cause unrealistically large errors in streamline tracing. For example, on visualizations with arrowheads, the neural network might yield a very strong edge orthogonal to the flow field positioned at the back of an arrowhead. If the algorithm considered only the edges at this point, it may make a significant error, despite the edges in nearby positions indicating the correct direction. We felt that creating an average over neighborhood was the more correct approach, and we found closer agreement with human performance with this change.
Qualitative Evaluation
Four different flow visualization methods were used in our evaluation of the theory. These were implementations of four of the six used by [Laidlaw et al. 2001]. We chose to investigate a regular arrow grid because it is still the most commonly used in practice and a jittered arrow grid because of the arguments that have been made that this should improve perceptual aliasing problems [Turk and Banks 1996]. We added Line Integral Convolution (LIC) because of its widespread advocation by the visualization community [Cabral and Leedom 1993] and head-to-tail aligned streaklets because of Laidlaw et al.'s finding that is was the best and the theoretical arguments in support of this method [Ware 2008]. Note that Laidlaw et al. used Turk and Banks algorithm to achieve aligned arrows on equally spaced streamlines while we used Jobard and Lefer's [Jobard and Lefer 1997] method to achieve the same effect and we used streaklets without an arrowhead [Fowler and Ware 1989].
 		                                                      

                            Fig. 3a. Regular arrows.                                                                                 Fig. 3b. Jittered arrows
V1 is known to have detectors at different scales. However, to make the problem computationally tractable we chose only a single scale for the V1 and designed the data visualizations with elements scaled such that they were effectively detected by the gabor filter used by the model. The widths of the arrows and streaklets were chosen to be smaller than the central excitatory band of the gabor filter. This allowed the edge to be detected even if not precisely centered on the receptive field of the neuron. The spatial frequency of the LIC visualization is defined by the texture over which the vector field is convoluted. Our texture was created by generating a texture of random white noise of one-third the necessary size and scaling it up via. interpolation. The resulting spacial frequency of the LIC visualization was of a scale that was effectively detected by the gabor filters of the model.
4.1.1 Regular Arrows (Figure 3a). This visualization is produced by placing arrow glyphs at regular spacings. The magnitude of the vector field is indicated by the arrow length, and the flow direction by the arrow head. The grid underlying the regular arrows is apparent to humans, but the edge weights of the model show no obvious signs of being negatively affected. In fact, the regularity ensures that the arrows are well spaced, preventing any false edge responses that might be produced by the interference of multiple arrows. We can expect that nontangential edge responses will be produced by the arrowheads and these will lead to errors in the streamline advection task.
4.1.1.1. Jittered arrows (Figure 3b). This visualization is similar to the regular arrows, but the arrows are moved a small random distance from the regular locations. While composed of the same basic elements as the regular grid, we see instances where nearby arrows interfere with each other and produce edge responses nontangential to the flow direction. Also, as with gridded arrows, the arrowheads will excite neurons with orientation selectivity nontangential to the flow. This can be seen in Figure 4a. In this figure, we can see orthogonal neural excitation to each side of the upper arrow, caused by the back edge of the arrowhead (blue circles). We can also see excitation caused by the interference of two arrows at the bottom right (green circle). These nontangential responses are much stronger than those found in the aligned streaklets visualization (Figure 4b).

                                                                             
   Fig. 4a. Closeup of neural response to arrowheads                      Fig. 4b. Closeup of neural response to aligned streaklets.**
DISCUSSION
The overall agreement between the pattern of results for human observers and the V1-based model provides strong support of the perceptual theory we outlined in the introduction. The aligned arrows style of visualization produced clear chains of mutually reinforcing neurons along the flow path in the representation, making the flow pathway easy to trace as predicted by theory.
The fact that LIC produced results as good as the equally spaced streamlines was something of a surprise, and this lends support to its popularity within the visualization community. While it did not produce as much neuron excitation as the aligned arrows method, this was offset by the lack of nontangential edge responses produced by glyph-based visualizations. However, its good performance was achieved only because our evaluation method ignored the directional ambiguity inherent in this method. [Laidlaw et al. 2001] found this method to be the worst and there is little doubt that had we allowed flow in any direction, up or down, human observers would have found pathways with close to 180 degrees of error half of the time.
The performance of both the model and the human test subjects is likely to be highly dependent on the underlying vector field used. As described in Section 5.1.6, the vector field was generated by interpolating between an 8x8 grid of random, but generally upward pointing vectors. A consequence of this is that when adjacent vectors in this grid point somewhat toward each other, the vector field forms an area of convergence. This convergence area tends to funnel neighboring streamline paths together, reducing error in streamline tracing (Figure 3 is an example of this). Thus, the overall accuracies of both the model and human subjects may be higher than might be might be observed using a vector field without such convergence zones.
We were surprised that the computer algorithm actually did better at the task than human observers. One reason for this may have been that humans would have to make saccadic eye movements to trace a path, whereas the computer did not. For the patterns we used, it is likely that the observers had to make fixations on several successive parts of a path, and errors may have accumulated as they resumed a trace from a previous fixation. Nevertheless, we feel that the algorithm could easily be adjusted to make it give results closer to human subjects. A more sophisticated approach would be to simulate eye fixations.
The model we applied is a considerable simplification over what actually occurs. It only uses the simplest model of the simplest orientation sensitive neurons, and fails to include cortical magnification, among other shortcomings. Real cortical receptive fields are not arranged in a rigid hexagonal grid as they are in Li's model. Furthermore, the neurons of V1 respond to many frequencies, however our model only uses one in its present form. In addition, besides the so-called simple cells modeled by [Li 1998], other neurons in V1 and V2 called complex and hypercomplex cells all have important functions. For example, end-stopped cell respond best to a contour that terminates in the receptive field and understanding these may be important in showing how the direction of flow along a contour can be unambiguously shown. Moreover, visual information is processed through several stages following the primary cortex, including V2, V4 and the IT cortex. Each of these appears to abstract more complex, less localized patterns. Researchers are far from having sufficient information to model the operations of these stages all of which may have a role in tracing contours. Nevertheless, the results are compelling and there are advantages in having a relatively simple model. We have plans to add some of these more complex functions in future versions of the model.
TYPICAL REFERENCES IN NEW ACM REFERENCE FORMAT
A paginated journal article [Abril and Plant 2007], an enumerated journal article [Cohen et al. 2007], a reference to an entire issue [Cohen 1996], a monograph (whole book) [Kosiur 2001], a monograph/whole book in a series (see 2a in spec. document) [Harel 1979], a divisible-book such as an anthology or compilation [Editor 2007] followed by the same example, however we only output the series if the volume number is given [Editor 2008] (so Editor00a’s series should NOT be present since it has no vol. no.), a chapter in a divisible book [Spector 1990], a chapter in a divisible book in a series [Douglass et al. 1998], a multi-volume work as book [Knuth 1997], an article in a proceedings (of a conference, symposium, workshop for example) (paginated proceedings article) [Andler 1979], a proceedings article with all possible elements [Smith 2010], an example of an enumerated proceedings article [Gundy et al. 2007], an informally published work [Harel 1978], a doctoral dissertation [Clarkson 1985], a master’s thesis: [Anisi 2003], an online document / world wide web resource [Thornburg 2001], [Ablamowicz and Fauser 2007], [Poker-Edge.Com 2006], a video game (Case 1) [Obama 2008] and (Case 2) [Novak 2003] and [Lee 2005] and (Case 3) a patent   Scientist 2009], work accepted for publication [Rous 2008], ‘YYYYb’-test for prolific author [Saeedi et al. 2010a] and [Saeedi et al. 2010b]. Other cites might contain ‘duplicate’ DOI and URLs (some SIAM articles) [Kirschmer and Voight 2010]. Boris / Barbara Beeton: multi-volume works as books [Hörmander 1985b] and [Hörmander 1985a].
APPENDIX
With closest point to a given set of lines we intend the point having the minimum Euclidean distance with respect to those lines. Typically, this problem is formulated using Plücker coordinates. Instead, here we compute this point by solving the problem in a closed form, since the resulting matrices are not ill-conditioned in our case. More precisely, by indicating the set of n lines with
		(2)
where Oi is the origin of the ith line and di is the corresponding direction (normalized), we found the closest point by minimizing
		(3)
The distance  can be written as
		(4)
The minimization is obtained by substituting (4) in (3), and imposing the derivative to zero. After some simple algebra, we obtain the final formulation:
		(5)
REFERENCES
Rafal Ablamowicz and Bertfried Fauser. 2007. CLIFFORD: a Maple 11 Package for Clifford Algebra Computations, version 11. (2007). Retrieved February 28, 2008 from http://math.tntech.edu/rafal/cliff11/index.html
Patricia S. Abril and Robert Plant. 2007. The patent holder’s dilemma: Buy, sell, or troll? Commun. ACM 50, 1 (Jan. 2007), 36–44.   DOI:http://dx.doi.org/10.1145/1188913.1188915
Sten Andler. 1979. Predicate Path expressions. In Proceedings of the 6th. ACM SIGACT-SIGPLAN symposium on Principles of Programming Languages (POPL ’79). ACM Press, New York, NY, 226–236. DOI:http://dx.doi.org/10.1145/567752.567774 
David A. Anisi. 2003. Optimal Motion Control of a Ground Vehicle. Master’s thesis. Royal Institute of Technology (KTH), Stockholm, Sweden.
Brian Cabral and Leith C. Leedom. 1993. Imaging vector fields using line integral convolution. In Proceedings of the 20th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH’93). ACM, New York, NY, 263–270. DOI:http://dx.doi.org/10.1145/166117.166151
Kenneth L. Clarkson. 1985. Algorithms for Closest-Point Problems (Computational Geometry). Ph.D. Dissertation. Stanford University, Palo Alto, CA. UMI Order Number: AAT 8506171.
Jacques Cohen (Ed.). 1996. Special Issue: Digital Libraries. Commun. ACM 39, 11 (Nov. 1996).
Sarah Cohen, Werner Nutt, and Yehoshua Sagic. 2007. Deciding equivalances among conjunctive aggregate queries. J. ACM 54, 2, Article 5 (April 2007), 50 pages. DOI:http://dx.doi.org/10.1145/1219092.1219093
John G. Daugman. 1985. Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two dimensional visual cortical filters. J. Optical Soc. Amer. A: Optics, Image Science, Vision 2, 7 (1985), 1160–1169.
Bruce P. Douglass, David Harel, and Mark B. Trakhtenbrot. 1998. Statecarts in use: structured analysis and object-orientation. In Lectures on Embedded Systems, Grzegorz Rozenberg and Frits W. Vaandrager (Eds.). Lecture Notes in Computer Science, Vol. 1494. Springer-Verlag, London, 368–394. DOI:http://dx.doi.org/10.1007/3-540-65193-4 29
Ian Editor (Ed.). 2007. The title of book one (1st. ed.). The name of the series one, Vol. 9. University of Chicago Press, Chicago. DOI:http://dx.doi.org/10.1007/3-540-09237-4
Ian Editor (Ed.). 2008. The title of book two (2nd. ed.). University of Chicago Press, Chicago, Chapter 100.  DOI:http://dx.doi.org/10.1007/3-540-09237-4
David J. Field, Anthony Hayes, and Robert F. Hess. 1993. Contour integration by the human visual system: Evidence for a local “association field”. Vision Res. 33, 2 (1993), 173–193. DOI:http://dx.doi.org/10.1016/0042-6989(93)90156-Q
David Fowler and Colin Ware. 1989. Strokes for Representing Univariate Vector Field Maps. In Proceedings of Graphics Interface. Canadian Human-Computer Communications Society, Mississauga, Ontario, 249–253.
Matthew Van Gundy, Davide Balzarotti, and Giovanni Vigna. 2007. Catch me, if you can: Evading network signatures with web-based polymorphic worms. In Proceedings of the first USENIX workshop on Offensive Technologies (WOOT ’07). USENIX Association, Berkley, CA, Article 7, 9 pages.
David Harel. 1978. LOGICS of Programs: AXIOMATICS and DESCRIPTIVE POWER. MIT Research Lab Technical Report TR-200. Massachusetts Institute of Technology, Cambridge, MA.
David Harel. 1979. First-Order Dynamic Logic. Lecture Notes in Computer Science, Vol. 68. Springer-Verlag, New York, NY. DOI: :http://dx.doi.org/10.1007/3-540-09237-4
Lars Hörmander. 1985a. The analysis of linear partial differential operators. III. Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences], Vol. 275. Springer-Verlag, Berlin, Germany. viii+525 pages. Pseudodifferential operators.
Lars Hörmander. 1985b. The analysis of linear partial differential operators. IV. Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences], Vol. 275. Springer-Verlag, Berlin, Germany. vii+352 pages. Fourier integral operators.
David H. Hubel and Torsten N. Wiesel. 1962. Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex. J. Physiol. 160, 1 (1962), 106–154. http://jp.physoc.org
David H. Hubel and Torsten N. Wiesel. 1968. Receptive fields and functional architecture of monkey striate cortex. (1968). http://jp.physoc.org/cgi/content/abstract/195/1/215 http://www.hubel/papers/uconn.html.
Bruno Jobard and Wilfrid Lefer. 1997. Creating evenly-spaced streamlines of arbitrary density. In Proceedings of the Eurographics Workshop. Springer Verlag, Berlin, 43–56.
Markus Kirschmer and John Voight. 2010. Algorithmic Enumeration of Ideal Classes for Quaternion Orders. SIAM J. Comput. 39, 5 (Jan. 2010), 1714–1747. DOI:http://dx.doi.org/10.1137/080734467
Donald E. Knuth. 1997. The Art of Computer Programming, Vol. 1: Fundamental Algorithms (3rd. ed.). Addison Wesley Longman Publishing Co., Inc.
David Kosiur. 2001. Understanding Policy-Based Networking (2nd. ed.). Wiley, New York, NY.
David H. Laidlaw, J. Scott Davidson, Timothy S. Miller, Marco da Silva, R. M. Kirby, William H. Warren, and Michael Tarr. 2001. Quantitative comparative evaluation of 2D vector field visualization methods. In Proceedings of the Conference on Visualization (VIS’01). IEEE Computer Society, Los Alamitos, CA, 143–150.
Newton Lee. 2005. Interview with Bill Kinder: January 13, 2005. Video, Comput. Entertain. 3, 1, Article 4 (Jan.-March 2005). DOI:http://dx.doi.org/10.1145/1057270.1057278
Zhaoping Li. 1998. A neural model of contour integration in the primary visual cortex. Neural Comput. 10, 4 (1998), 903–940. DOI:http://dx.doi.org/10.1162/089976698300017557
Nick Lund. 2001. Attention and Pattern Recognition. Routledge, New York, NY.
Dave Novak. 2003. Solder man. Video. In ACM SIGGRAPH 2003 Video Review on Animation theater Program: Part I - Vol. 145 (July 27–27, 2003). ACM Press, New York, NY, 4. DOI:http://dx.doi.org/99.9999/woot07-S422
Barack Obama. 2008. A more perfect union. Video. (5 March 2008). Retrieved March 21, 2008 from http://video.google.com/videoplay?docid=6528042696351994555
Daniel Pineo and Colin Ware. 2008. Neural modeling of flow rendering effectiveness. In Proceedings of the 5th Symposium on Applied Perception in Graphics and Visualization (APGV’08). ACM, New York, NY, 171–178. DOI:http://dx.doi.org/10.1145/1394281.1394313
Poker-Edge.Com. 2006. Stats and Analysis. (March 2006).  Retrieved June 7, 2006 from http://www.poker-edge.com/stats.php
Bernard Rous. 2008. The Enabling of Digital Libraries. Digital Libraries 12, 3, Article 5 (July 2008). To appear.
Mehdi Saeedi, Morteza Saheb Zamani, and Mehdi Sedighi. 2010a. A library-based synthesis methodology for reversible logic. Microelectron. J. 41, 4 (April 2010), 185–194.
Mehdi Saeedi, Morteza Saheb Zamani, Mehdi Sedighi, and Zahra Sasanian. 2010b. Synthesis of Reversible Circuit Using Cycle-Based Approach. J. Emerg. Technol. Comput. Syst. 6, 4 (Dec. 2010).
Joseph Scientist. 2009. The fountain of youth. (Aug. 2009). Patent No. 12345, Filed July 1st., 2008, Issued Aug. 9th., 2009.
Stan W. Smith. 2010. An experiment in bibliographic mark-up: Parsing metadata for XML export. In Proceedings of the 3rd. annual workshop on Librarians and Computers (LAC ’10), Reginald N. Smythe and Alexander Noble (Eds.), Vol. 3. Paparazzi Press, Milan Italy, 422–431. DOI:http://dx.doi.org/99.9999/woot07-S422
Asad Z. Spector. 1990. Achieving application requirements. In Distributed Systems (2nd. ed.), Sape Mullender (Ed.). ACM Press, New York, NY, 19–33. DOI:http://dx.doi.org/10.1145/90417.90738
Harry Thornburg. 2001. Introduction to Bayesian Statistics. (March 2001). Retrieved March 2, 2005 from http://ccrma.stanford.edu/~jos/bayes/bayes.html
Greg Turk and David Banks. 1996. Image-guided streamline placement. Technical Report I-CA2200. University of California, Santa Barbara, CA. 453–460 pages. DOI:http://dx.doi.org/10.1145/237170.237285
Colin Ware. 2008. Toward a Perceptual Theory of Flow Visualization. IEEE Comput. Graph. Appl. 28, 2 (2008), 6–11. DOI:http://dx.doi.org/10.1109/MCG.2008.39


Received February 2007;  revised July 2009;  accepted October 2009
Online Appendix to: Neural Modeling of Flow Rendering Effectiveness
DANIEL PINEO and COLIN WARE, University of New Hampshire SEAN FOGARTY, University of Illinois at Urbana-Champaign
A. Analysis of Invalid Trials
A.1. Results
Invalid trials were previously defined as those trials in which the subject pressed the space bar to end the trial without first bringing the virtual finger to a stop. The number of invalid trials for each subject is presented by feedback condition in Figure 12. Due to the irregular distribution of the data, no significance test was run. However, the figure shows two notable features. First, Subject 6 had more invalid trials than any other subject. Second, more invalid trials occurred under the proprioceptive-only (NV + P) feedback condition than any other.
A.2. Discussion
Although the number of invalid trials is not directly related to task performance, we now consider any trends that may be seen in this information. No statistical tests were done with this data, but some inferences can be drawn from the invalid trial counts in Figure 12. The only obvious trend is that the NV + P condition appears to have the most invalid trials, which is the case for all but two subjects. In the post-experiment survey, one subject commented on this trend, saying that with only proprioceptive motion feedback it was hard to tell if the finger was moving or not. This might be a result of a larger threshold for absolute motion detection for proprioceptive feedback than for visual feedback. This difficulty in stopping the finger did not appear to affect the ease of use ratings provided by subjects, as no correlation was observed with invalid trial counts.
It is interesting to note that the no-feedback condition (NV + NP) had fewer invalid trials than the proprioceptive-only condition (NV + P), especially in light of the findings of Ghez et al. [1990] that deafferented individuals tend to display endpoint drift in non-sighted targeted reaching movements (equivalent to NV + NP condition) while neurologically normal individuals do not (equivalent to NV + P condition). A notable difference between our study and the study by Ghez et al. is the availability of kinesthetic feedback from the thumb pressing on the force sensor, which indicates the magnitude of the applied force, that is, the movement command in our study. Thus, under the no-feedback condition, subjects could use this information to learn to apply grasping forces within the dead zone to stop finger movement. When motion feedback is available, subjects are likely focusing more on the feedback than on the forces applied, since the feedback allows them to achieve better accuracy. Thus, at the end of a trial, subjects are most likely using this feedback as an indicator of zero velocity rather than attending to the applied force. When visual feedback is available, it is easy to determine whether the finger is moving or not; however, when only proprioceptive feedback is available, the finger can be moving slowly without the subject being aware of its motion. This explanation would result in a larger number of failed trials for the NV + P condition than for any other, as observed. 
